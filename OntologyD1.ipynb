{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "521ae1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.13/site-packages (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f5aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the variables from .env into the system environment\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the key\n",
    "api_key = os.getenv(\"LLAMA_API_KEY\")\n",
    "\n",
    "if api_key:\n",
    "    print(\"API Key loaded successfully!\")\n",
    "else:\n",
    "    print(\"Error: API Key not found. Check your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "491c11c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for .env at: /Users/mc/Desktop/FD1/.env\n",
      "Key found: e9f357c0ee4ac7a50e9f12bcdff50267c189c095819017ad913f26d6816ce092\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# This finds the directory where your script is located\n",
    "env_path = Path('.') / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "print(f\"Looking for .env at: {os.path.abspath(env_path)}\")\n",
    "print(f\"Key found: {os.getenv('LLAMA_API_KEY')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fd77f76",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2939728674.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[15], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip install rdflib python-dotenvpip install rdflib python-dotenv\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install rdflib python-dotenvpip install rdflib python-dotenv\n",
    "pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b587e658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries installed and ready for mapping!\n"
     ]
    }
   ],
   "source": [
    "import rdflib\n",
    "import dotenv\n",
    "print(\"Libraries installed and ready for mapping!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c93cfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping complete! Created enriched_ontology.owl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from rdflib import Graph, Namespace, URIRef, Literal, RDF, RDFS, OWL\n",
    "\n",
    "# 1. Load your JSON and Ontology\n",
    "with open('/Users/mc/Downloads/ontology_ready_metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "g = Graph()\n",
    "g.parse(\"/Users/mc/Downloads/data_democratization_ontology.owl\", format=\"xml\")\n",
    "\n",
    "# 2. Define Namespaces (must match your .owl file)\n",
    "EX = Namespace(\"http://example.org/fanduel/data-democratization-ontology#\")\n",
    "g.bind(\"ex\", EX)\n",
    "\n",
    "def map_metadata_to_owl():\n",
    "    # Loop through tables in JSON\n",
    "    for table in metadata['tables']:\n",
    "        # Create a unique URI for the table\n",
    "        # We sanitize the physical name to use as a fragment\n",
    "        table_uri = EX[table['physical_name'].replace('.', '_')]\n",
    "        \n",
    "        # Assign Type: EnrichedTable or BaseTable\n",
    "        table_type = EX.EnrichedTable if table['table_type'] == \"ENRICHED\" else EX.BaseTable\n",
    "        g.add((table_uri, RDF.type, table_type))\n",
    "        \n",
    "        # Add metadata properties\n",
    "        g.add((table_uri, RDFS.label, Literal(table['physical_name'])))\n",
    "        g.add((table_uri, EX.assetName, Literal(table['physical_name'])))\n",
    "        g.add((table_uri, EX.businessDefinition, Literal(table['description'])))\n",
    "\n",
    "        # Map Columns\n",
    "        for col in table['columns']:\n",
    "            # Create unique Column URI (Table_Column)\n",
    "            col_uri = EX[f\"{table['physical_name'].replace('.', '_')}_{col['name']}\"]\n",
    "            g.add((col_uri, RDF.type, EX.Column))\n",
    "            g.add((col_uri, EX.assetName, Literal(col['name'])))\n",
    "            g.add((col_uri, EX.inferredDatatype, Literal(f\"xsd:{col['data_type']}\")))\n",
    "            \n",
    "            # Link Column to Table\n",
    "            g.add((table_uri, EX.hasColumn, col_uri))\n",
    "            g.add((col_uri, EX.belongsToTable, table_uri))\n",
    "\n",
    "    # 3. Save the enriched ontology\n",
    "    g.serialize(destination=\"enriched_ontology.owl\", format=\"xml\")\n",
    "    print(\"Mapping complete! Created enriched_ontology.owl\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    map_metadata_to_owl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1ea52d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Llama 3 Mapping Logic ---\n",
      "Here is an example of how you can use the `rdflib` library in Python to map a JSON relationship type `'belongs_to'` to an OWL property `ex:relatedToTable`:\n",
      "```\n",
      "from rdflib import URIRef, Literal\n",
      "from rdflib.namespace import RDFS\n",
      "\n",
      "# Define the namespace for the ex prefix\n",
      "ex = URIRef(\"http://example.org/\")\n",
      "\n",
      "# Create a new RDF graph\n",
      "g = Graph()\n",
      "\n",
      "# Define the OWL property 'ex:relatedToTable'\n",
      "related_to_table = URIRef(ex + \"relatedToTable\")\n",
      "\n",
      "# Define the JSON relationship type 'belongs_to' as an RDF term\n",
      "belongs_to = Literal(\"belongs_to\", lang=\"json\")\n",
      "\n",
      "# Map the JSON relationship type to the OWL property\n",
      "g.add((URIRef(ex + \"Table\"), RDFS.relatedTo, related_to_table))\n",
      "g.add((related_to_table, RDFS.label, belongs_to))\n",
      "\n",
      "print(g.serialize(format=\"turtle\"))\n",
      "```\n",
      "This code defines a new RDF graph `g` and creates an OWL property `ex:relatedToTable`. It then maps the JSON relationship type `'belongs_to'` to this property using the `RDFS.relatedTo` predicate. Finally, it serializes the graph to Turtle format.\n",
      "\n",
      "Note that in this example, we're using the `Literal` class from `rdflib` to represent the JSON relationship type as an RDF term. The `lang=\"json\"` parameter indicates that the literal is a JSON string.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import sys\n",
    "\n",
    "def get_llama_mapping_logic(prompt):\n",
    "    try:\n",
    "        response = ollama.chat(model='llama3', messages=[\n",
    "            {'role': 'user', 'content': f\"Write Python rdflib code for: {prompt}\"}\n",
    "        ])\n",
    "        return response['message']['content']\n",
    "    except Exception as e:\n",
    "        return f\"\\nCONNECTION ERROR: Ensure 'ollama serve' is running in your terminal. \\nDetails: {e}\"\n",
    "\n",
    "# Test the connection\n",
    "print(\"--- Llama 3 Mapping Logic ---\")\n",
    "result = get_llama_mapping_logic(\"Map JSON relationship_type 'belongs_to' to OWL property 'ex:relatedToTable'\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84fb7ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created enriched_ontology.owl!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from rdflib import Graph, Namespace, URIRef, Literal, RDF, RDFS, XSD\n",
    "\n",
    "# 1. Setup Namespaces (Must match your .owl file precisely)\n",
    "EX = Namespace(\"http://example.org/fanduel/data-democratization-ontology#\")\n",
    "PROV = Namespace(\"http://www.w3.org/ns/prov#\")\n",
    "\n",
    "def enrich_ontology():\n",
    "    # Load JSON data\n",
    "    with open('/Users/mc/Downloads/ontology_ready_metadata.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Load existing Ontology\n",
    "    g = Graph()\n",
    "    g.parse(\"/Users/mc/Downloads/data_democratization_ontology.owl\", format=\"xml\")\n",
    "    g.bind(\"ex\", EX)\n",
    "    g.bind(\"prov\", PROV)\n",
    "\n",
    "    # 2. Map Tables\n",
    "    for table in data['tables']:\n",
    "        # Create a URI-safe name (e.g., replacing dots with underscores)\n",
    "        safe_name = table['physical_name'].replace('.', '_')\n",
    "        table_uri = EX[safe_name]\n",
    "\n",
    "        # Determine Class: EnrichedTable or BaseTable\n",
    "        table_class = EX.EnrichedTable if table['table_type'] == \"ENRICHED\" else EX.BaseTable\n",
    "        g.add((table_uri, RDF.type, table_class))\n",
    "        \n",
    "        # Add Data Properties\n",
    "        g.add((table_uri, RDFS.label, Literal(table['physical_name'])))\n",
    "        g.add((table_uri, EX.assetName, Literal(table['physical_name'])))\n",
    "        g.add((table_uri, EX.businessDefinition, Literal(table['description'])))\n",
    "\n",
    "        # 3. Map Columns\n",
    "        for col in table['columns']:\n",
    "            col_uri = EX[f\"{safe_name}_{col['name']}\"]\n",
    "            g.add((col_uri, RDF.type, EX.Column))\n",
    "            g.add((col_uri, EX.assetName, Literal(col['name'])))\n",
    "            g.add((col_uri, EX.inferredDatatype, Literal(f\"xsd:{col['data_type']}\")))\n",
    "            \n",
    "            # Create Relationships\n",
    "            g.add((table_uri, EX.hasColumn, col_uri))\n",
    "            g.add((col_uri, EX.belongsToTable, table_uri))\n",
    "\n",
    "    # 4. Map Relationships (Lineage/Joins)\n",
    "    for rel in data.get('relationships', []):\n",
    "        source_uri = EX[rel['source_table'].replace('.', '_')]\n",
    "        target_uri = EX[rel['target_table'].replace('.', '_')]\n",
    "        \n",
    "        # Using a loose relationship property from your ontology\n",
    "        g.add((source_uri, EX.relatedToTable, target_uri))\n",
    "\n",
    "    # Save the new file\n",
    "    g.serialize(destination=\"enriched_ontology.owl\", format=\"xml\")\n",
    "    print(\"Successfully created enriched_ontology.owl!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    enrich_ontology()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d25ec60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating FanDuel Business Context for: foundation.financial.ledger_lines_enriched...\n",
      "Generating FanDuel Business Context for: foundation.financial.withdrawals_enriched_v4...\n",
      "Generating FanDuel Business Context for: foundation.financial.ledger_lines_enriched_v1...\n",
      "Generating FanDuel Business Context for: foundation.financial.deposits_enriched_v1...\n",
      "Generating FanDuel Business Context for: foundation.account.verified_user_details...\n",
      "Generating FanDuel Business Context for: foundation.account.verification_attempt_v1...\n",
      "Generating FanDuel Business Context for: foundation.account.authgateway_session_created_events...\n",
      "Generating FanDuel Business Context for: foundation.financial.ledger_account_balances_v1...\n",
      "Generating FanDuel Business Context for: foundation.financial.deposits_v4...\n",
      "Generating FanDuel Business Context for: foundation.financial.withdrawals_v4...\n",
      "Generating FanDuel Business Context for: foundation.financial.worldpay_transactions...\n",
      "Success: fanduel_smart_metadata.owl created with Llama 3 intelligence.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from rdflib import Graph, Namespace, Literal, RDF\n",
    "\n",
    "# 1. Setup Environment\n",
    "EX = Namespace(\"http://example.org/fanduel/data-democratization-ontology#\")\n",
    "g = Graph()\n",
    "g.parse(\"enriched_ontology.owl\", format=\"xml\")\n",
    "\n",
    "def get_fan_duel_inference(asset_name, columns, existing_relations):\n",
    "    \"\"\"\n",
    "    FanDuel-specific prompt to infer business logic from raw Databricks metadata.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    CONTEXT (FanDuel Data Lake):\n",
    "    Technical Table: {asset_name}\n",
    "    Technical Columns: {', '.join(columns)}\n",
    "    Existing Ontological Links: {', '.join(existing_relations)}\n",
    "\n",
    "    TASK:\n",
    "    1. Define 'Purpose': Explain what this table does for a FanDuel Business Analyst (e.g., wallet management, fraud detection, marketing).\n",
    "    2. 'Composable Join': Suggest which table this should join with to create a '360 View' of the customer (e.g., joining ledger lines with user profiles).\n",
    "    3. 'Governance Risk': Rate 1-5 how sensitive this is for GDPR/AML compliance.\n",
    "    4. 'Example Query': Write a simple SQL snippet that a user could copy/paste.\n",
    "\n",
    "    FORMAT:\n",
    "    Purpose: [text]\n",
    "    JoinSuggestion: [Table Name]\n",
    "    RiskScore: [1-5]\n",
    "    SQLSnippet: [SQL code]\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ollama.chat(model='llama3', messages=[{'role': 'user', 'content': prompt}])\n",
    "    return response['message']['content']\n",
    "\n",
    "def enhance_fanduel_ontology():\n",
    "    # Loop through tables identified in your OWL file\n",
    "    for table_uri in g.subjects(RDF.type, None):\n",
    "        if (table_uri, RDF.type, EX.EnrichedTable) in g or (table_uri, RDF.type, EX.BaseTable) in g:\n",
    "            asset_name = str(g.value(table_uri, EX.assetName))\n",
    "            # Extract technical columns to give Llama 3 context\n",
    "            columns = [str(g.value(c, EX.assetName)) for c in g.objects(table_uri, EX.hasColumn)]\n",
    "            # Extract existing relations (e.g., relatedToTable)\n",
    "            relations = [str(o).split('#')[-1] for o in g.objects(table_uri, EX.relatedToTable)]\n",
    "            \n",
    "            print(f\"Generating FanDuel Business Context for: {asset_name}...\")\n",
    "            ai_output = get_fan_duel_inference(asset_name, columns, relations)\n",
    "            \n",
    "            # Semantic Integration Logic\n",
    "            lines = ai_output.split('\\n')\n",
    "            for line in lines:\n",
    "                if line.startswith(\"Purpose:\"):\n",
    "                    g.set((table_uri, EX.businessDefinition, Literal(line.replace(\"Purpose:\", \"\").strip())))\n",
    "                if line.startswith(\"SQLSnippet:\"):\n",
    "                    g.set((table_uri, EX.exampleQuery, Literal(line.replace(\"SQLSnippet:\", \"\").strip())))\n",
    "                if line.startswith(\"RiskScore:\"):\n",
    "                    score = line.replace(\"RiskScore:\", \"\").strip()\n",
    "                    g.set((table_uri, EX.governanceScore, Literal(int(score) * 20))) # Scale 1-5 to 0-100\n",
    "\n",
    "    g.serialize(destination=\"fanduel_smart_metadata.owl\", format=\"xml\")\n",
    "    print(\"Success: fanduel_smart_metadata.owl created with Llama 3 intelligence.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    enhance_fanduel_ontology()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
